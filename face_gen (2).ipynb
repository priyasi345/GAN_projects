{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_gen.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylav93uKI0PX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDeW0uwNJtXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from keras import preprocessing\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,Dropout,Dense,Flatten,Conv2DTranspose,BatchNormalization,LeakyReLU,Reshape\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vj61n_tJtm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_celeb = []\n",
        "train_path_celeb = \"/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba/\"\n",
        "for path in os.listdir(train_path_celeb):\n",
        "    if '.jpg' in path:\n",
        "        path_celeb.append(os.path.join(train_path_celeb, path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42ooLLyUJ2b4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_path=path_celeb[0:50000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7JF9fYPJ5J6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "crop = (30, 55, 150, 175) #croping size for the image so that only the face at centre is obtained\n",
        "images = [np.array((Image.open(path).crop(crop)).resize((64,64))) for path in new_path]\n",
        "\n",
        "for i in range(len(images)):\n",
        "    images[i] = ((images[i] - images[i].min())/(255 - images[i].min()))\n",
        "    #images[i] = images[i]*2-1  #uncomment this if activation is tanh for generator last layer\n",
        "    \n",
        "images = np.array(images) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALqnGQQnJ5kL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data=images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ-mgKF0J82l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(path_celeb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFpknSGlJ_tq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3yqy4sAKCTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "fig,ax=plt.subplots(2,5)\n",
        "fig.suptitle(\"Real Images\")\n",
        "idx=800\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(5):\n",
        "            ax[i,j].imshow(train_data[idx].reshape(64,64,3))\n",
        "            #ax[i,j].set_title(\"Real Image\")\n",
        "            \n",
        "            idx+=600\n",
        "            \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqOEqAf6KCqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji3yrTSxKI6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise_shape = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnY6K5wXKJRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator=Sequential()\n",
        "generator.add(Dense(4*4*512,input_shape=[noise_shape]))\n",
        "generator.add(Reshape([4,4,512]))\n",
        "generator.add(Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"))\n",
        "generator.add(LeakyReLU(alpha=0.2))\n",
        "generator.add(BatchNormalization())\n",
        "generator.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"))\n",
        "generator.add(LeakyReLU(alpha=0.2))\n",
        "generator.add(BatchNormalization())\n",
        "generator.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\"))\n",
        "generator.add(LeakyReLU(alpha=0.2))\n",
        "generator.add(BatchNormalization())\n",
        "generator.add(Conv2DTranspose(3, kernel_size=4, strides=2, padding=\"same\",\n",
        "                                 activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiti_6qgKNw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLasZ9z9KOCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator=Sequential()\n",
        "discriminator.add(Conv2D(32, kernel_size=4, strides=2, padding=\"same\",input_shape=[64,64, 3]))\n",
        "discriminator.add(Conv2D(64, kernel_size=4, strides=2, padding=\"same\"))\n",
        "discriminator.add(LeakyReLU(0.2))\n",
        "discriminator.add(BatchNormalization())\n",
        "discriminator.add(Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\n",
        "discriminator.add(LeakyReLU(0.2))\n",
        "discriminator.add(BatchNormalization())\n",
        "discriminator.add(Conv2D(256, kernel_size=4, strides=2, padding=\"same\"))\n",
        "discriminator.add(LeakyReLU(0.2))\n",
        "discriminator.add(Flatten())\n",
        "discriminator.add(Dropout(0.5))\n",
        "discriminator.add(Dense(1,activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfOO7kStKTSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUlA3pADKYR8",
        "colab_type": "text"
      },
      "source": [
        "DCGAN (combined model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWl-dhcmKYpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GAN =Sequential([generator,discriminator])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIbpIOO4Kan3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator.compile(optimizer='adam',loss='binary_crossentropy')\n",
        "discriminator.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zzhs6wW2Kcp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GAN.compile(optimizer='adam',loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V3cZ0qfKgAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GAN.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8kDUwm_Kh30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GAN.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYo-7fWgKjUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 300  #set epoch according to your training dataset size,i had chosen 50k images hence epochs are high as 300...\n",
        "batch_size = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4lTJMc3KnfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_loss=[] #list to collect loss for the discriminator model\n",
        "G_loss=[] #list to collect loss for generator model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC23b31CKrFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.device('/gpu:0'):\n",
        " for epoch in range(epochs):\n",
        "    print(f\"Currently on Epoch {epoch+1}\")\n",
        "    \n",
        "    # For every batch in the dataset\n",
        "    for i in range(X_train.shape[0]//batch_size):\n",
        "        \n",
        "        if (i)%100 == 0:\n",
        "            print(f\"\\tCurrently on batch number {i} of {len(X_train)//batch_size}\")\n",
        "            \n",
        "        noise=np.random.uniform(-1,1,size=[batch_size,noise_shape])\n",
        "        \n",
        "        gen_image = generator.predict_on_batch(noise)\n",
        "        \n",
        "        train_dataset = X_train[i*batch_size:(i+1)*batch_size]\n",
        "        #train on real image\n",
        "        train_label=np.ones(shape=(batch_size,1))\n",
        "        discriminator.trainable = True\n",
        "        d_loss1 = discriminator.train_on_batch(train_dataset,train_label)\n",
        "        \n",
        "        #train on fake image\n",
        "        train_label=np.zeros(shape=(batch_size,1))\n",
        "        d_loss2 = discriminator.train_on_batch(gen_image,train_label)\n",
        "        \n",
        "        \n",
        "        noise=np.random.uniform(-1,1,size=[batch_size,noise_shape])\n",
        "        train_label=np.ones(shape=(batch_size,1))\n",
        "        discriminator.trainable = False\n",
        "        #train the generator\n",
        "        g_loss = GAN.train_on_batch(noise, train_label)\n",
        "        D_loss.append(d_loss1+d_loss2)\n",
        "        G_loss.append(g_loss)\n",
        "        \n",
        "         \n",
        "    if epoch % 5 == 0:\n",
        "        samples = 10\n",
        "        x_fake = generator.predict(np.random.normal(loc=0, scale=1, size=(samples,100)))\n",
        "\n",
        "        for k in range(samples):\n",
        "            plt.subplot(2, 5, k+1)\n",
        "            plt.imshow(x_fake[k].reshape(64,64,3))\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    print('Epoch: %d,  Loss: D_real = %.3f, D_fake = %.3f,  G = %.3f' %   (epoch+1, d_loss1, d_loss2, g_loss))        \n",
        "print('Training is complete')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw1Z3ex6K8yd",
        "colab_type": "text"
      },
      "source": [
        "Output Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcJor1OrKrah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise=np.random.uniform(-1,1,size=[500,noise_shape])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byl-J2nFK_mQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im=generator.predict(noise)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmJ1FYTLLBmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(5):\n",
        " plt.figure(figsize=(7,7))   \n",
        " for k in range(20):\n",
        "            noise=np.random.uniform(-1,1,size=[100,noise_shape])\n",
        "            im=generator.predict(noise) \n",
        "            plt.subplot(5, 4, k+1)\n",
        "            plt.imshow(im[k].reshape(64,64,3))\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        " \n",
        " plt.tight_layout()\n",
        " plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4FxplvuLIKl",
        "colab_type": "text"
      },
      "source": [
        "Loss Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y03zuTDLERa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(G_loss,color='red',label='Generator_loss')\n",
        "plt.plot(D_loss,color='blue',label='Discriminator_loss')\n",
        "plt.legend()\n",
        "plt.xlabel('total batches')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Model loss per batch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-o7tlPcLODk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "Pkl_Filename = \"DCGAN.pkl\"  \n",
        "\n",
        "with open(Pkl_Filename, 'wb') as file:  \n",
        "    pickle.dump(GAN, file)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}